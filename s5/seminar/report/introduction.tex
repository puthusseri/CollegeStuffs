\chapter{Introduction}
Deep learning is an artificial intelligence function that imitates the workings of the human brain in processing data and creating patterns for use in decision making. Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network. Deep Learning is about learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text.
\par
The resolution and quality of images produced by generative methods — especially generative adversarial networks (GAN)
have seen rapid improvement recently. Yet the generators continue to operate as black
boxes, and despite recent efforts, the understanding of various aspects of the image synthesis process, e.g., the ori-
gin of stochastic features, is still lacking. The properties of
the latent space are also poorly understood, and the commonly demonstrated latent space interpolations provide no quantitative way to compare different generators
against each other.
Motivated by style transfer literature, re-designing of the generator architecture in a way that exposes novel ways to control the image synthesis process. Our generator starts
from a learned constant input and adjusts the “style” of the image at each convolution layer based on the latent code, therefore directly controlling the strength of image
features at different scales. Combined with noise injected directly into the network, this architectural change leads to automatic, unsupervised separation of high-level attributes
(e.g., pose, identity) from stochastic variation (e.g., freck-
les, hair) in the generated images, and enables intuitive
scale-specific mixing and interpolation operations. We do
not modify the discriminator or the loss function in any
way, and our work is thus orthogonal to the ongoing discussion about GAN loss functions, regularization, and hyperparameters.
Our generator embeds the input latent code into an intermediate latent space, which has a profound effect on how the factors of variation are represented in the network. The
input latent space must follow the probability density of the
training data, and we argue that this leads to some degree of
unavoidable entanglement. Our intermediate latent space
is free from that restriction and is therefore allowed to be
disentangled. As previous methods for estimating the degree of latent space disentanglement are not directly applicable in our case, we propose two new automated metrics perceptual path length and linear separability — for quantifying these aspects of the generator. Using these metrics, we
show that compared to a traditional generator architecture,
our generator admits a more linear, less entangled representation of different factors of variation.
The result of the style based GAN was a new dataset of human faces
(Flickr-Faces-HQ, FFHQ) that offers much higher quality and covers considerably wider variation than existing
high-resolution datasets.
